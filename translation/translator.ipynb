{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from google.transliteration import transliterate_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset hatexplain (C:/Users/dange/.cache/huggingface/datasets/hatexplain/plain_text/1.0.0/df474d8d8667d89ef30649bf66e9c856ad8305bef4bc147e8e31cbdf1b8e0249)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b9154f7a524e39905870fc67727476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"hatexplain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(dataset, split, max_len=200):\n",
    "    dataset = dataset[split].to_dict()\n",
    "    del dataset['id']\n",
    "    num_examples = len(dataset['post_tokens'])\n",
    "    print(f'{split} has {num_examples} examples')\n",
    "    dataset['label'] = torch.zeros((num_examples, 3))\n",
    "    label = []\n",
    "    for i in range(num_examples):\n",
    "        label.append(torch.Tensor(torch.Tensor(dataset['annotators'][i]['label']).type(torch.IntTensor)))\n",
    "    label = torch.stack(label)\n",
    "    label = label.mode().values\n",
    "    dataset['label'][torch.arange(num_examples).type(torch.LongTensor), label.type(torch.LongTensor)] = 1\n",
    "    dataset['class'] = label\n",
    "    rationales = []\n",
    "    for rationale in dataset['rationales']:\n",
    "        if len(rationale) == 0:\n",
    "            rationales.append(torch.zeros((max_len)))\n",
    "            continue\n",
    "        r = np.concatenate((\n",
    "            np.array(rationale[0]), np.zeros((max_len - len(rationale[0])))\n",
    "        )).astype(bool)\n",
    "        for i in range(1, len(rationale)):\n",
    "            r += np.concatenate((\n",
    "                np.array(rationale[i]), np.zeros((max_len - len(rationale[i])))\n",
    "            )).astype(bool)\n",
    "        rationales.append(torch.tensor((r).astype(int)))\n",
    "    dataset['rationales'] = torch.stack(rationales)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 15383 examples\n",
      "validation has 1922 examples\n",
      "test has 1924 examples\n"
     ]
    }
   ],
   "source": [
    "train = create_dataframe(dataset, 'train')\n",
    "validation = create_dataframe(dataset, 'validation')\n",
    "test = create_dataframe(dataset, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train class split:-  tensor([4748, 6251, 4384]) \n",
      " validation class split:-  tensor([593, 781, 548]) \n",
      " test class split:-  tensor([594, 782, 548])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"train class split:- \", train['class'].bincount(), \"\\n\",\n",
    "    \"validation class split:- \", validation['class'].bincount(), \"\\n\",\n",
    "    \"test class split:- \", test['class'].bincount(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX LENGTH:- 165\n",
      "AVG LENGTH:- 23.465253851654424\n"
     ]
    }
   ],
   "source": [
    "sent_len = []\n",
    "for sent in train['post_tokens']:\n",
    "    sent_len.append(len(sent))\n",
    "print(f'MAX LENGTH:- {max(sent_len)}\\nAVG LENGTH:- {sum(sent_len)/len(sent_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "stratified_shuffle = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_language_splits(dataset, shuffler):\n",
    "    shuffler.get_n_splits(dataset['post_tokens'], dataset['class'])\n",
    "    for en_index, hi_index in shuffler.split(dataset['post_tokens'], dataset['class']):\n",
    "        en_dataset = {}\n",
    "        hi_dataset = {}\n",
    "\n",
    "        en_dataset['index'] = en_index\n",
    "        hi_dataset['index'] = hi_index\n",
    "\n",
    "        en_dataset['label'] = torch.index_select(dataset['label'], 0, torch.tensor(en_index))\n",
    "        hi_dataset['label'] = torch.index_select(dataset['label'], 0, torch.tensor(hi_index))\n",
    "\n",
    "        en_dataset['rationales'] = torch.index_select(dataset['rationales'], 0, torch.tensor(en_index))\n",
    "        hi_dataset['rationales'] = torch.index_select(dataset['rationales'], 0, torch.tensor(hi_index))\n",
    "\n",
    "        en_dataset['class'] = torch.tensor([dataset['class'][i] for i in en_index])\n",
    "        hi_dataset['class'] = torch.tensor([dataset['class'][i] for i in hi_index])\n",
    "\n",
    "        en_dataset['post_tokens'] = [dataset['post_tokens'][i] for i in en_index]\n",
    "        hi_dataset['post_tokens'] = [dataset['post_tokens'][i] for i in hi_index]\n",
    "\n",
    "    return en_dataset, hi_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train, hi_train = generate_language_splits(train, stratified_shuffle)\n",
    "en_validation, hi_validation = generate_language_splits(validation, stratified_shuffle)\n",
    "en_test, hi_test = generate_language_splits(test, stratified_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train class split:-  tensor([ 950, 1250,  877]) \n",
      " validation class split:-  tensor([119, 156, 110]) \n",
      " test class split:-  tensor([119, 156, 110])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"train class split:- \", hi_train['class'].bincount(), \"\\n\",\n",
    "    \"validation class split:- \", hi_validation['class'].bincount(), \"\\n\",\n",
    "    \"test class split:- \", hi_test['class'].bincount(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transliterator = {}\n",
    "transliterator['sentence'] = []\n",
    "transliterator['index'] = []\n",
    "transliterator['words'] = []\n",
    "transliterator['type'] = []\n",
    "for i in range(hi_train['class'].shape[0]):\n",
    "    transliterator['type'].append('train')\n",
    "    transliterator['sentence'].append(\" \".join(hi_train['post_tokens'][i]))\n",
    "    transliterator['index'].append(hi_train['index'][i])\n",
    "    mask = hi_train['rationales'][i, :]\n",
    "    transliterator['words'].append(\n",
    "        \" \".join([word for i, word in enumerate(hi_train['post_tokens'][i]) if i < 200 and mask[i]])\n",
    "    )\n",
    "for i in range(hi_validation['class'].shape[0]):\n",
    "    transliterator['type'].append('validation')\n",
    "    transliterator['sentence'].append(\" \".join(hi_validation['post_tokens'][i]))\n",
    "    transliterator['index'].append(hi_validation['index'][i])\n",
    "    mask = hi_validation['rationales'][i, :]\n",
    "    transliterator['words'].append(\n",
    "        \" \".join([word for i, word in enumerate(hi_validation['post_tokens'][i]) if i < 200 and mask[i]])\n",
    "    )\n",
    "for i in range(hi_test['class'].shape[0]):\n",
    "    transliterator['type'].append('test')\n",
    "    transliterator['sentence'].append(\" \".join(hi_test['post_tokens'][i]))\n",
    "    transliterator['index'].append(hi_test['index'][i])\n",
    "    mask = hi_test['rationales'][i, :]\n",
    "    transliterator['words'].append(\n",
    "        \" \".join([word for i, word in enumerate(hi_test['post_tokens'][i]) if i < 200 and mask[i]])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(transliterator)\n",
    "df.to_csv('to_translate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_df = pd.read_csv('../translation/translated.csv', usecols=['sentence', 'hindi_sentence', 'words', 'hindi_words', 'index', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>index</th>\n",
       "      <th>words</th>\n",
       "      <th>type</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>hindi_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mass unmarked moslem graves would</td>\n",
       "      <td>2980</td>\n",
       "      <td>mass unmarked moslem graves</td>\n",
       "      <td>train</td>\n",
       "      <td>बड़े पैमाने पर अचिह्नित मोस्लेम कब्रें</td>\n",
       "      <td>बड़े पैमाने पर अचिह्नित मोस्लेम कब्रें</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;user&gt; i see she will get inside the elevator ...</td>\n",
       "      <td>4992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;user&gt; मैं देख रहा हूं</td>\n",
       "      <td>#VALUE!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luckily the iranian people did not bite to the...</td>\n",
       "      <td>3962</td>\n",
       "      <td>scum rulers of the western world</td>\n",
       "      <td>train</td>\n",
       "      <td>सौभाग्य से ईरानी लोगों ने अपनी सरकार के खिलाफ ...</td>\n",
       "      <td>पश्चिमी दुनिया के स्कम शासक</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it an incident you hear that incident if it wa...</td>\n",
       "      <td>10205</td>\n",
       "      <td>it an incident you hear that incident if it wa...</td>\n",
       "      <td>train</td>\n",
       "      <td>यह एक घटना है कि आप उस घटना को सुनते हैं यदि य...</td>\n",
       "      <td>यह एक घटना है कि आप उस घटना को सुनते हैं यदि य...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i just grow tired of seeing queer folx get can...</td>\n",
       "      <td>12567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>मैं बस क्वीर फोलक्स को दैनिक रूप से डिब्बाबंद ...</td>\n",
       "      <td>#VALUE!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>please address the issue of white kids quotati...</td>\n",
       "      <td>1892</td>\n",
       "      <td>white kids quotations for obvious reasons bein...</td>\n",
       "      <td>test</td>\n",
       "      <td>कृपया मुस्लिम ग्रूमिंग गैंग्स रॉदरहैम द्वारा प...</td>\n",
       "      <td>सफेद बच्चों के उद्धरण स्पष्ट कारणों के लिए पूर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>it ’ payday bitches</td>\n",
       "      <td>1252</td>\n",
       "      <td>bitches</td>\n",
       "      <td>test</td>\n",
       "      <td>यह 'payday bitches</td>\n",
       "      <td>वो साले</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>getting paid biweekly is so ghetto</td>\n",
       "      <td>1332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>भुगतान किया जा रहा है, यहूदी बस्ती है</td>\n",
       "      <td>#VALUE!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>&lt;user&gt; big head and being a faggot in the fron...</td>\n",
       "      <td>1020</td>\n",
       "      <td>faggot</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;उपयोगकर्ता&gt; बड़ा सिर और सामने की पंक्ति में ए...</td>\n",
       "      <td>होमोसेक्सुअल</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>&lt;user&gt; i fucking hate you he mumbles looking u...</td>\n",
       "      <td>1824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;user&gt; मैं तुम्हें नफरत करता हूँ तुम उसे देख र...</td>\n",
       "      <td>#VALUE!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1925 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  index  \\\n",
       "0                     mass unmarked moslem graves would   2980   \n",
       "1     <user> i see she will get inside the elevator ...   4992   \n",
       "2     luckily the iranian people did not bite to the...   3962   \n",
       "3     it an incident you hear that incident if it wa...  10205   \n",
       "4     i just grow tired of seeing queer folx get can...  12567   \n",
       "...                                                 ...    ...   \n",
       "1920  please address the issue of white kids quotati...   1892   \n",
       "1921                                it ’ payday bitches   1252   \n",
       "1922                 getting paid biweekly is so ghetto   1332   \n",
       "1923  <user> big head and being a faggot in the fron...   1020   \n",
       "1924  <user> i fucking hate you he mumbles looking u...   1824   \n",
       "\n",
       "                                                  words   type  \\\n",
       "0                           mass unmarked moslem graves  train   \n",
       "1                                                   NaN  train   \n",
       "2                      scum rulers of the western world  train   \n",
       "3     it an incident you hear that incident if it wa...  train   \n",
       "4                                                   NaN  train   \n",
       "...                                                 ...    ...   \n",
       "1920  white kids quotations for obvious reasons bein...   test   \n",
       "1921                                            bitches   test   \n",
       "1922                                                NaN   test   \n",
       "1923                                             faggot   test   \n",
       "1924                                                NaN   test   \n",
       "\n",
       "                                         hindi_sentence  \\\n",
       "0                बड़े पैमाने पर अचिह्नित मोस्लेम कब्रें   \n",
       "1                                <user> मैं देख रहा हूं   \n",
       "2     सौभाग्य से ईरानी लोगों ने अपनी सरकार के खिलाफ ...   \n",
       "3     यह एक घटना है कि आप उस घटना को सुनते हैं यदि य...   \n",
       "4     मैं बस क्वीर फोलक्स को दैनिक रूप से डिब्बाबंद ...   \n",
       "...                                                 ...   \n",
       "1920  कृपया मुस्लिम ग्रूमिंग गैंग्स रॉदरहैम द्वारा प...   \n",
       "1921                                 यह 'payday bitches   \n",
       "1922              भुगतान किया जा रहा है, यहूदी बस्ती है   \n",
       "1923  <उपयोगकर्ता> बड़ा सिर और सामने की पंक्ति में ए...   \n",
       "1924  <user> मैं तुम्हें नफरत करता हूँ तुम उसे देख र...   \n",
       "\n",
       "                                            hindi_words  \n",
       "0                बड़े पैमाने पर अचिह्नित मोस्लेम कब्रें  \n",
       "1                                               #VALUE!  \n",
       "2                           पश्चिमी दुनिया के स्कम शासक  \n",
       "3     यह एक घटना है कि आप उस घटना को सुनते हैं यदि य...  \n",
       "4                                               #VALUE!  \n",
       "...                                                 ...  \n",
       "1920  सफेद बच्चों के उद्धरण स्पष्ट कारणों के लिए पूर...  \n",
       "1921                                            वो साले  \n",
       "1922                                            #VALUE!  \n",
       "1923                                       होमोसेक्सुअल  \n",
       "1924                                            #VALUE!  \n",
       "\n",
       "[1925 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hindi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_alphabets = [\n",
    "    \"क\",\"ख\",\"ग\",\"घ\",\"ङ\",\"च\",\"छ\",\"ज\",\"झ\",\"ञ\",\"ट\",\"ठ\",\"ड\",\"ढ\",\"ण\",\"त\",\"थ\",\"द\",\"ध\",\"न\",\"प\",\"फ\",\"ब\",\"भ\",\"म\",\"य\",\"र\",\"ल\",\"व\",\"श\",\"ष\",\"स\",\"ह\",\"क्ष\",\"त्र\",\"ज्ञ\"    \n",
    "    ]\n",
    "def normalize(input):\n",
    "    input_type = type(input)\n",
    "    if input_type == str:\n",
    "        input = input.split()\n",
    "    output = []\n",
    "    for word in input:\n",
    "        norm = []\n",
    "        for char in list(word):\n",
    "            if char in hindi_alphabets:\n",
    "                norm.append(char)\n",
    "        output.append(\"\".join(norm))\n",
    "    if input_type == str:\n",
    "        return \" \".join(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence', 'index', 'words', 'type', 'hindi_sentence', 'hindi_words'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_dict = hindi_df.to_dict()\n",
    "translated_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_sentences = hindi_df.hindi_sentence.values\n",
    "hindi_words = hindi_df.hindi_words.values\n",
    "english_words = hindi_df.words.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1429d3bf3e407c818d6b33f825a4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12394 words mapped out of 67149\n",
      "1792 rationales found out of 1925\n"
     ]
    }
   ],
   "source": [
    "hindi_rationales = []\n",
    "transliterations = pickle.load(open('transliterations.p', 'rb'))\n",
    "total_words = 0\n",
    "matches_found = 0\n",
    "sentences_matched = 0\n",
    "MATCHED = False\n",
    "for i, sentence in enumerate(tqdm(hindi_sentences)):\n",
    "    sentence = sentence.split()\n",
    "    rationale = torch.zeros(1, len(sentence))\n",
    "    total_words += len(hindi_words[i])\n",
    "    if hindi_words[i] == '#VALUE!':\n",
    "        hindi_rationales.append(rationale)\n",
    "        sentences_matched += 1\n",
    "        continue\n",
    "    transliterated_words = transliterations[i]\n",
    "    if type(hindi_words[i]) != list: \n",
    "        hindi_words[i] = hindi_words[i].split() \n",
    "    if type(english_words[i]) != list: \n",
    "        english_words[i] = english_words[i].split()\n",
    "    #     for word in english_words[i]:\n",
    "    #         transliterated_words.extend(transliterate_word(word, lang_code='hi'))\n",
    "    # transliterations.append(transliterated_words)\n",
    "    normalized_hindi_words = normalize(hindi_words[i])\n",
    "    normalized_trans_words = normalize(transliterated_words)\n",
    "    for j, word in enumerate(sentence):\n",
    "        if word in hindi_words[i] or word in english_words[i] or word in transliterated_words:\n",
    "            matches_found += 1\n",
    "            rationale[0,j] = 1\n",
    "            if not MATCHED:\n",
    "                sentences_matched += 1\n",
    "                MATCHED = True\n",
    "        elif normalize(word) in normalized_hindi_words or normalize(word) in normalized_trans_words:\n",
    "            matches_found += 1\n",
    "            rationale[0, j] = 1\n",
    "            if not MATCHED:\n",
    "                sentences_matched += 1\n",
    "                MATCHED = True\n",
    "    if not MATCHED:\n",
    "        hindi_rationales.append(None)\n",
    "    else:\n",
    "        hindi_rationales.append(rationale)\n",
    "    MATCHED = False\n",
    "    if i == 500:\n",
    "        break\n",
    "print(f'{matches_found} words mapped out of {total_words}\\n{sentences_matched} rationales found out of {hindi_df.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dange\\.conda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:576: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  values = np.array([convert(v) for v in values])\n",
      "c:\\Users\\dange\\.conda\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:576: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  values = np.array([convert(v) for v in values])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>index</th>\n",
       "      <th>words</th>\n",
       "      <th>type</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>hindi_words</th>\n",
       "      <th>hindi_rationales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mass unmarked moslem graves would</td>\n",
       "      <td>2980</td>\n",
       "      <td>[mass, unmarked, moslem, graves]</td>\n",
       "      <td>train</td>\n",
       "      <td>बड़े पैमाने पर अचिह्नित मोस्लेम कब्रें</td>\n",
       "      <td>[बड़े, पैमाने, पर, अचिह्नित, मोस्लेम, कब्रें]</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;user&gt; i see she will get inside the elevator ...</td>\n",
       "      <td>4992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;user&gt; मैं देख रहा हूं</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luckily the iranian people did not bite to the...</td>\n",
       "      <td>3962</td>\n",
       "      <td>[scum, rulers, of, the, western, world]</td>\n",
       "      <td>train</td>\n",
       "      <td>सौभाग्य से ईरानी लोगों ने अपनी सरकार के खिलाफ ...</td>\n",
       "      <td>[पश्चिमी, दुनिया, के, स्कम, शासक]</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it an incident you hear that incident if it wa...</td>\n",
       "      <td>10205</td>\n",
       "      <td>[it, an, incident, you, hear, that, incident, ...</td>\n",
       "      <td>train</td>\n",
       "      <td>यह एक घटना है कि आप उस घटना को सुनते हैं यदि य...</td>\n",
       "      <td>[यह, एक, घटना, है, कि, आप, उस, घटना, को, सुनते...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i just grow tired of seeing queer folx get can...</td>\n",
       "      <td>12567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>मैं बस क्वीर फोलक्स को दैनिक रूप से डिब्बाबंद ...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>please address the issue of white kids quotati...</td>\n",
       "      <td>1892</td>\n",
       "      <td>[white, kids, quotations, for, obvious, reason...</td>\n",
       "      <td>test</td>\n",
       "      <td>कृपया मुस्लिम ग्रूमिंग गैंग्स रॉदरहैम द्वारा प...</td>\n",
       "      <td>[सफेद, बच्चों, के, उद्धरण, स्पष्ट, कारणों, के,...</td>\n",
       "      <td>[[tensor(0.), tensor(1.), tensor(1.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>it ’ payday bitches</td>\n",
       "      <td>1252</td>\n",
       "      <td>[bitches]</td>\n",
       "      <td>test</td>\n",
       "      <td>यह 'payday bitches</td>\n",
       "      <td>[वो, साले]</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(1.)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>getting paid biweekly is so ghetto</td>\n",
       "      <td>1332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>भुगतान किया जा रहा है, यहूदी बस्ती है</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>&lt;user&gt; big head and being a faggot in the fron...</td>\n",
       "      <td>1020</td>\n",
       "      <td>[faggot]</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;उपयोगकर्ता&gt; बड़ा सिर और सामने की पंक्ति में ए...</td>\n",
       "      <td>[होमोसेक्सुअल]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>&lt;user&gt; i fucking hate you he mumbles looking u...</td>\n",
       "      <td>1824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;user&gt; मैं तुम्हें नफरत करता हूँ तुम उसे देख र...</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1925 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  index  \\\n",
       "0                     mass unmarked moslem graves would   2980   \n",
       "1     <user> i see she will get inside the elevator ...   4992   \n",
       "2     luckily the iranian people did not bite to the...   3962   \n",
       "3     it an incident you hear that incident if it wa...  10205   \n",
       "4     i just grow tired of seeing queer folx get can...  12567   \n",
       "...                                                 ...    ...   \n",
       "1920  please address the issue of white kids quotati...   1892   \n",
       "1921                                it ’ payday bitches   1252   \n",
       "1922                 getting paid biweekly is so ghetto   1332   \n",
       "1923  <user> big head and being a faggot in the fron...   1020   \n",
       "1924  <user> i fucking hate you he mumbles looking u...   1824   \n",
       "\n",
       "                                                  words   type  \\\n",
       "0                      [mass, unmarked, moslem, graves]  train   \n",
       "1                                                   NaN  train   \n",
       "2               [scum, rulers, of, the, western, world]  train   \n",
       "3     [it, an, incident, you, hear, that, incident, ...  train   \n",
       "4                                                   NaN  train   \n",
       "...                                                 ...    ...   \n",
       "1920  [white, kids, quotations, for, obvious, reason...   test   \n",
       "1921                                          [bitches]   test   \n",
       "1922                                                NaN   test   \n",
       "1923                                           [faggot]   test   \n",
       "1924                                                NaN   test   \n",
       "\n",
       "                                         hindi_sentence  \\\n",
       "0                बड़े पैमाने पर अचिह्नित मोस्लेम कब्रें   \n",
       "1                                <user> मैं देख रहा हूं   \n",
       "2     सौभाग्य से ईरानी लोगों ने अपनी सरकार के खिलाफ ...   \n",
       "3     यह एक घटना है कि आप उस घटना को सुनते हैं यदि य...   \n",
       "4     मैं बस क्वीर फोलक्स को दैनिक रूप से डिब्बाबंद ...   \n",
       "...                                                 ...   \n",
       "1920  कृपया मुस्लिम ग्रूमिंग गैंग्स रॉदरहैम द्वारा प...   \n",
       "1921                                 यह 'payday bitches   \n",
       "1922              भुगतान किया जा रहा है, यहूदी बस्ती है   \n",
       "1923  <उपयोगकर्ता> बड़ा सिर और सामने की पंक्ति में ए...   \n",
       "1924  <user> मैं तुम्हें नफरत करता हूँ तुम उसे देख र...   \n",
       "\n",
       "                                            hindi_words  \\\n",
       "0         [बड़े, पैमाने, पर, अचिह्नित, मोस्लेम, कब्रें]   \n",
       "1                                               #VALUE!   \n",
       "2                     [पश्चिमी, दुनिया, के, स्कम, शासक]   \n",
       "3     [यह, एक, घटना, है, कि, आप, उस, घटना, को, सुनते...   \n",
       "4                                               #VALUE!   \n",
       "...                                                 ...   \n",
       "1920  [सफेद, बच्चों, के, उद्धरण, स्पष्ट, कारणों, के,...   \n",
       "1921                                         [वो, साले]   \n",
       "1922                                            #VALUE!   \n",
       "1923                                     [होमोसेक्सुअल]   \n",
       "1924                                            #VALUE!   \n",
       "\n",
       "                                       hindi_rationales  \n",
       "0     [[tensor(1.), tensor(1.), tensor(1.), tensor(1...  \n",
       "1     [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "2     [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "3     [[tensor(1.), tensor(1.), tensor(1.), tensor(1...  \n",
       "4     [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "...                                                 ...  \n",
       "1920  [[tensor(0.), tensor(1.), tensor(1.), tensor(0...  \n",
       "1921             [[tensor(0.), tensor(0.), tensor(1.)]]  \n",
       "1922  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "1923                                               None  \n",
       "1924  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...  \n",
       "\n",
       "[1925 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'hindi_rationales' in hindi_df.columns:\n",
    "    print(\"cleaning . . . \")\n",
    "    hindi_df.drop(columns=['hindi_rationales'], inplace=True)\n",
    "    hindi_df.dropna()\n",
    "hindi_df = pd.concat([hindi_df, pd.DataFrame(hindi_rationales, columns=['hindi_rationales'])], axis=1)\n",
    "display(hindi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_english(en_dict, index, label, rationale, output, post_tokens):\n",
    "    en_dict['index'] = np.concatenate((en_dict['index'], np.array([index])))\n",
    "    en_dict['label'] = np.concatenate((en_dict['label'], label.reshape(1,3)))\n",
    "    en_dict['rationales'] = np.concatenate((en_dict['rationales'], rationale.reshape(1, 200)))\n",
    "    en_dict['class'] = np.concatenate((en_dict['class'], np.array([output])))\n",
    "    en_dict['post_tokens'].append(post_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'label', 'rationales', 'class', 'post_tokens'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final(translated_dict, en_dict, hi_dict, hindi_df):\n",
    "    for i, row in enumerate(hindi_df.iterrows()):\n",
    "        _, row = row\n",
    "        if row[-1] == None:\n",
    "            append_to_english(en_dict, row[1], hi_dict['label'][i], hi_dict['rationales'][i], hi_dict['class'][i], hi_dict['post_tokens'][i])\n",
    "        else:\n",
    "            translated_dict['index'].append(row[1])\n",
    "            translated_dict['label'].append(hi_dict['label'][i])\n",
    "            translated_dict['rationales'].append(row[-1])\n",
    "            translated_dict['class'].append(hi_dict['class'][i])\n",
    "            translated_dict['post_tokens'].append(row[4].split(\" \"))\n",
    "    translated_dict['label'] = torch.stack(translated_dict['label'])\n",
    "    translated_dict['class'] = torch.stack(translated_dict['class'])\n",
    "    rationales = []\n",
    "    for rationale in translated_dict['rationales']:\n",
    "        r = np.concatenate(\n",
    "            (rationale, \n",
    "                np.zeros((1, 200 - rationale.shape[1]))\n",
    "            ), axis=1).astype(bool)\n",
    "        rationales.append(torch.tensor((r).astype(int)))\n",
    "    translated_dict['rationales'] = torch.stack(rationales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_hi_train = {}\n",
    "translated_hi_validation = {}\n",
    "translated_hi_test = {}\n",
    "\n",
    "for key in en_train.keys():\n",
    "    translated_hi_train[key] = []\n",
    "    translated_hi_validation[key] = []\n",
    "    translated_hi_test[key] = []\n",
    "\n",
    "groups = hindi_df.groupby('type')\n",
    "generate_final(translated_hi_train, en_train, hi_train, groups.get_group('train'))\n",
    "generate_final(translated_hi_validation, en_validation, hi_validation, groups.get_group('validation'))\n",
    "generate_final(translated_hi_test, en_test, hi_test, groups.get_group('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train class split:-  tensor([448, 589, 401]) \n",
      " validation class split:-  tensor([55, 76, 52]) \n",
      " test class split:-  tensor([51, 71, 49])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"train class split:- \", translated_hi_train['class'].bincount(), \"\\n\",\n",
    "    \"validation class split:- \", translated_hi_validation['class'].bincount(), \"\\n\",\n",
    "    \"test class split:- \", translated_hi_test['class'].bincount(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train class split:-  tensor([3838, 5043, 3526]) \n",
      " validation class split:-  tensor([478, 629, 440]) \n",
      " test class split:-  tensor([481, 634, 446])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"train class split:- \", torch.tensor(en_train['class']).bincount(), \"\\n\",\n",
    "    \"validation class split:- \", torch.tensor(en_validation['class']).bincount(), \"\\n\",\n",
    "    \"test class split:- \", torch.tensor(en_test['class']).bincount(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4286, 5632, 3927]) tensor([533, 705, 492]) tensor([532, 705, 495])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    torch.tensor(en_train['class']).bincount() + translated_hi_train['class'].bincount(), \n",
    "torch.tensor(en_validation['class']).bincount() + translated_hi_validation['class'].bincount(), \n",
    "torch.tensor(en_test['class']).bincount() + translated_hi_test['class'].bincount()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train class split:-  tensor([4748, 6251, 4384]) \n",
      " validation class split:-  tensor([593, 781, 548]) \n",
      " test class split:-  tensor([594, 782, 548])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"train class split:- \", train['class'].bincount(), \"\\n\",\n",
    "    \"validation class split:- \", validation['class'].bincount(), \"\\n\",\n",
    "    \"test class split:- \", test['class'].bincount(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(en_train, open('../data/en_train.p', 'wb'))\n",
    "pickle.dump(en_validation, open('../data/en_validation.p', 'wb'))\n",
    "pickle.dump(en_test, open('../data/en_test.p', 'wb'))\n",
    "\n",
    "pickle.dump(translated_hi_train, open('../data/hi_train.p', 'wb'))\n",
    "pickle.dump(translated_hi_validation, open('../data/hi_validation.p', 'wb'))\n",
    "pickle.dump(translated_hi_test, open('../data/hi_test.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c165b169ead51ed7dd867ada967038e7afce51eef97009d1ebd4bca797cfdb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
